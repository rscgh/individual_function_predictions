{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare White-Matter Connecitvity Blueprints\n",
    "\n",
    "This notebook loads all non-redundant individual level HCP task contrasts, \n",
    "optionally residualizes them based on the group average task contrasts, and concatenates them into a single file.\n",
    "\n",
    "**Inputs**\n",
    "\n",
    "Indiviudal task contrasts<br>\n",
    "`HCP_1200/{subj}/MNINonLinear/Results/tfMRI_{para}/tfMRI_{para}_hp200_s2_level2_MSMAll.feat/{subj}_tfMRI_{para}_level2_hp200_s2_MSMAll.dscalar.nii`, \n",
    "\n",
    "**Outputs**\n",
    "\n",
    "List of non-redundant HPC task contrasts<br>\n",
    "`data/task_contrasts_47_unique_names.txt`\n",
    "\n",
    "Indiviudal task contrasts (254 x 47 contrasts in single file)<br>\n",
    "`/scratch/users/robert.scholz2/acc_dists/all_47_tasks_254_full_unrelated.raw.npy`\n",
    "\n",
    "Indiviudal task contrasts, residualized on group average contrasts (254 x 47 contrasts in single file)<br>\n",
    "`/scratch/users/robert.scholz2/acc_dists/all_47_tasks_254_full_unrelated.raw.npy`<br>\n",
    "\\+ residualization parameters `/scratch/users/robert.scholz2/acc_dists/all_47_tasks_254_full_unrelated.yresid.from_zscored.params.npy`\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/users/robert.scholz2/.local/lib/python3.9/site-packages/nilearn/datasets/__init__.py:93: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "nib.imageglobals.logger.level = 40\n",
    "import os\n",
    "\n",
    "f= lambda str: eval(\"f'\" + f\"{str}\" + \"'\")\n",
    "\n",
    "import hcp_utils as hcp\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.default_config import contrast_info\n",
    "full_subjs=np.loadtxt(\"data/subjs_hcp254_full_unrelated.txt\").astype(int).astype(str);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect all 47 non-redundant tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasks: ['EMOTION', 'GAMBLING', 'LANGUAGE', 'MOTOR', 'RELATIONAL', 'SOCIAL', 'WM']\n",
      "Contrasts: 47 ['EMOTION_FACES', 'EMOTION_SHAPES', 'EMOTION_FACES-SHAPES', 'GAMBLING_PUNISH', 'GAMBLING_REWARD', 'GAMBLING_REWARD-PUNISH', 'LANGUAGE_MATH', 'LANGUAGE_STORY', 'LANGUAGE_STORY-MATH', 'MOTOR_CUE', 'MOTOR_LF', 'MOTOR_LH', 'MOTOR_RF', 'MOTOR_RH']\n"
     ]
    }
   ],
   "source": [
    "paradigms = np.unique([c[0] for c in contrast_info]).tolist()\n",
    "print(\"Tasks:\", paradigms)\n",
    "\n",
    "unique_contrasts_long = ['tfMRI_EMOTION_level2_FACES_hp200_s2_MSMAll', 'tfMRI_EMOTION_level2_SHAPES_hp200_s2_MSMAll', 'tfMRI_EMOTION_level2_FACES-SHAPES_hp200_s2_MSMAll', 'tfMRI_GAMBLING_level2_PUNISH_hp200_s2_MSMAll', 'tfMRI_GAMBLING_level2_REWARD_hp200_s2_MSMAll', 'tfMRI_GAMBLING_level2_REWARD-PUNISH_hp200_s2_MSMAll', 'tfMRI_LANGUAGE_level2_MATH_hp200_s2_MSMAll', 'tfMRI_LANGUAGE_level2_STORY_hp200_s2_MSMAll', 'tfMRI_LANGUAGE_level2_STORY-MATH_hp200_s2_MSMAll', 'tfMRI_MOTOR_level2_CUE_hp200_s2_MSMAll', 'tfMRI_MOTOR_level2_LF_hp200_s2_MSMAll', 'tfMRI_MOTOR_level2_LH_hp200_s2_MSMAll', 'tfMRI_MOTOR_level2_RF_hp200_s2_MSMAll', 'tfMRI_MOTOR_level2_RH_hp200_s2_MSMAll', 'tfMRI_MOTOR_level2_T_hp200_s2_MSMAll', 'tfMRI_MOTOR_level2_AVG_hp200_s2_MSMAll', 'tfMRI_MOTOR_level2_CUE-AVG_hp200_s2_MSMAll', 'tfMRI_MOTOR_level2_LF-AVG_hp200_s2_MSMAll', 'tfMRI_MOTOR_level2_LH-AVG_hp200_s2_MSMAll', 'tfMRI_MOTOR_level2_RF-AVG_hp200_s2_MSMAll', 'tfMRI_MOTOR_level2_RH-AVG_hp200_s2_MSMAll', 'tfMRI_MOTOR_level2_T-AVG_hp200_s2_MSMAll', 'tfMRI_RELATIONAL_level2_MATCH_hp200_s2_MSMAll', 'tfMRI_RELATIONAL_level2_REL_hp200_s2_MSMAll', 'tfMRI_RELATIONAL_level2_REL-MATCH_hp200_s2_MSMAll', 'tfMRI_SOCIAL_level2_RANDOM_hp200_s2_MSMAll', 'tfMRI_SOCIAL_level2_TOM_hp200_s2_MSMAll', 'tfMRI_SOCIAL_level2_TOM-RANDOM_hp200_s2_MSMAll', 'tfMRI_WM_level2_2BK_BODY_hp200_s2_MSMAll', 'tfMRI_WM_level2_2BK_FACE_hp200_s2_MSMAll', 'tfMRI_WM_level2_2BK_PLACE_hp200_s2_MSMAll', 'tfMRI_WM_level2_2BK_TOOL_hp200_s2_MSMAll', 'tfMRI_WM_level2_0BK_BODY_hp200_s2_MSMAll', 'tfMRI_WM_level2_0BK_FACE_hp200_s2_MSMAll', 'tfMRI_WM_level2_0BK_PLACE_hp200_s2_MSMAll', 'tfMRI_WM_level2_0BK_TOOL_hp200_s2_MSMAll', 'tfMRI_WM_level2_2BK_hp200_s2_MSMAll', 'tfMRI_WM_level2_0BK_hp200_s2_MSMAll', 'tfMRI_WM_level2_2BK-0BK_hp200_s2_MSMAll', 'tfMRI_WM_level2_BODY_hp200_s2_MSMAll', 'tfMRI_WM_level2_FACE_hp200_s2_MSMAll', 'tfMRI_WM_level2_PLACE_hp200_s2_MSMAll', 'tfMRI_WM_level2_TOOL_hp200_s2_MSMAll', 'tfMRI_WM_level2_BODY-AVG_hp200_s2_MSMAll', 'tfMRI_WM_level2_FACE-AVG_hp200_s2_MSMAll', 'tfMRI_WM_level2_PLACE-AVG_hp200_s2_MSMAll', 'tfMRI_WM_level2_TOOL-AVG_hp200_s2_MSMAll'];\n",
    "unique_contrasts = [uc[6:-16].replace(\"_level2\",\"\") for uc in unique_contrasts_long]\n",
    "#np.savetxt(\"data/task_contrasts_47_unique_names.txt\", unique_contrasts, fmt=\"%s\")\n",
    "print(\"Contrasts:\", len(unique_contrasts), unique_contrasts[:14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluded contrasts (because they are redundant):\n",
    "excluded_contrasts=[ 'tfMRI_EMOTION_level2_SHAPES-FACES_hp200_s2_MSMAll', 'tfMRI_GAMBLING_level2_PUNISH-REWARD_hp200_s2_MSMAll', 'tfMRI_LANGUAGE_level2_MATH-STORY_hp200_s2_MSMAll', 'tfMRI_MOTOR_level2_AVG-CUE_hp200_s2_MSMAll', 'tfMRI_MOTOR_level2_AVG-LF_hp200_s2_MSMAll', 'tfMRI_MOTOR_level2_AVG-LH_hp200_s2_MSMAll', 'tfMRI_MOTOR_level2_AVG-RF_hp200_s2_MSMAll', 'tfMRI_MOTOR_level2_AVG-RH_hp200_s2_MSMAll', 'tfMRI_MOTOR_level2_AVG-T_hp200_s2_MSMAll',  'tfMRI_RELATIONAL_level2_MATCH-REL_hp200_s2_MSMAll', 'tfMRI_SOCIAL_level2_RANDOM-TOM_hp200_s2_MSMAll', 'tfMRI_WM_level2_0BK-2BK_hp200_s2_MSMAll', 'tfMRI_WM_level2_AVG-BODY_hp200_s2_MSMAll', 'tfMRI_WM_level2_AVG-FACE_hp200_s2_MSMAll', 'tfMRI_WM_level2_AVG-PLACE_hp200_s2_MSMAll', 'tfMRI_WM_level2_AVG-TOOL_hp200_s2_MSMAll']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subj_full_task_data(subj, contrast_ids, paradigms, dtype=np.float32, v=False, ret_keys=False, \\\n",
    "                            local_dir = \"/scratch/users/robert.scholz2/\", bma_slice=slice(0, 29696)):\n",
    "  data = {}\n",
    "  for para in paradigms: \n",
    "    if v: print(para, end=\" \")\n",
    "    fn = local_dir + f\"HCP_1200/{subj}/MNINonLinear/Results/tfMRI_{para}/tfMRI_{para}_hp200_s2_level2_MSMAll.feat/{subj}_tfMRI_{para}_level2_hp200_s2_MSMAll.dscalar.nii\"\n",
    "    cifti = nib.load(fn)\n",
    "    cnames = cifti.header.get_axis(0).name;\n",
    "    darr = cifti.get_fdata()[:,bma_slice];\n",
    "    data.update( {name : darr[i] for i, name in enumerate(cnames)})\n",
    "  \n",
    "  if v: print(len(data.keys()))\n",
    "  dkeys = list(data.keys())\n",
    "  tdata = []\n",
    "  contained=[]\n",
    "  if contrast_ids == \"all\":\n",
    "    for key in dkeys:\n",
    "      if v: print(subj+\"_\"+cid[:-1], \"\\t\", keys[0])\n",
    "      tdata.append(data[key])\n",
    "      contained.append(key)\n",
    "  else:\n",
    "    for cid in contrast_ids:\n",
    "      keys = [x for x in dkeys if x.startswith(subj+\"_\"+cid[:-1])]\n",
    "      if v: print(subj+\"_\"+cid[:-1], \"\\t\", keys[0])\n",
    "      tdata.append(data[keys[0]])\n",
    "      contained.append(keys[0])\n",
    "  if ret_keys: return np.array(tdata).T.astype(dtype), contained;\n",
    "  return np.array(tdata).T.astype(dtype);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47,\n",
       " ['100206_tfMRI_EMOTION_level2_FACES_hp200_s2_MSMAll',\n",
       "  '100206_tfMRI_EMOTION_level2_SHAPES_hp200_s2_MSMAll',\n",
       "  '100206_tfMRI_EMOTION_level2_FACES-SHAPES_hp200_s2_MSMAll',\n",
       "  '100206_tfMRI_GAMBLING_level2_PUNISH_hp200_s2_MSMAll',\n",
       "  '100206_tfMRI_GAMBLING_level2_REWARD_hp200_s2_MSMAll',\n",
       "  '100206_tfMRI_GAMBLING_level2_REWARD-PUNISH_hp200_s2_MSMAll',\n",
       "  '100206_tfMRI_LANGUAGE_level2_MATH_hp200_s2_MSMAll',\n",
       "  '100206_tfMRI_LANGUAGE_level2_STORY_hp200_s2_MSMAll',\n",
       "  '100206_tfMRI_LANGUAGE_level2_STORY-MATH_hp200_s2_MSMAll',\n",
       "  '100206_tfMRI_MOTOR_level2_CUE_hp200_s2_MSMAll'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj0_task_names = load_subj_full_task_data(full_subjs[0], unique_contrasts, paradigms , ret_keys=1)[1]\n",
    "len(subj0_task_names), subj0_task_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 254/254 [16:39<00:00,  3.93s/it]\n"
     ]
    }
   ],
   "source": [
    "# accumulate all subjects\n",
    "data = {subj: load_subj_full_task_data(subj, unique_contrasts, paradigms, v=0) for subj in tqdm(full_subjs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"/scratch/users/robert.scholz2/acc_dists/all_47_tasks_254_full_unrelated.raw.npy\"#\n",
    "if not(os.path.exists(fn)): np.save(fn, data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4G /scratch/users/robert.scholz2/acc_dists/all_47_tasks_254_full_unrelated.raw.npy\n"
     ]
    }
   ],
   "source": [
    "!ls -ash {fn}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create residualized task maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.stats import residualize\n",
    "\n",
    "def residualize_subj_task_data(sdata, y_mean_task_maps):\n",
    "    n_tasks = y_mean_task_maps.shape[-1]\n",
    "    mparams = np.zeros((n_tasks, 2))\n",
    "    resid = np.zeros_like(sdata);\n",
    "    for tn in range( n_tasks):\n",
    "      tresid, reg = residualize(sdata[:,tn], y_mean_task_maps[:,tn], return_reg = 1)\n",
    "      mparams[tn,:] = reg.intercept_[0], reg.coef_[0,0] \n",
    "      resid[:,tn] = tresid;\n",
    "    return resid, mparams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sample subject data:\", yfull_task_data['100206'].shape)\n",
    "y_task_maps_raw = np.array([d for s,d in yfull_task_data.items()])\n",
    "print(y_task_maps_raw.shape)\n",
    "y_task_maps_zsc = scipy.stats.zscore(y_task_maps_raw, axis=1)\n",
    "y_mean_task_maps = y_task_maps_zsc.mean(0)\n",
    "print(y_mean_task_maps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resdata = {}\n",
    "resparam = {}\n",
    "for subj, sdata in tqdm(yfull_task_data.items()):\n",
    "  # need to be zscored first! \n",
    "  sdataz = scipy.stats.zscore(sdata, axis=0)\n",
    "  resid, mparams = residualize_subj_task_data(sdataz, y_mean_task_maps)\n",
    "  resdata[subj] = resid;\n",
    "  resparam[subj] = mparams;  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"/scratch/users/robert.scholz2/acc_dists/all_47_tasks_254_full_unrelated.yresid.from_zscored.npy\"\n",
    "np.save(fn, resdata)\n",
    "fn = \"/scratch/users/robert.scholz2/acc_dists/all_47_tasks_254_full_unrelated.yresid.from_zscored.params.npy\"\n",
    "np.save(fn, resparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_full_ymap(y_resid, y_mean_task_maps, params):\n",
    "  return y_resid + ((y_mean_task_maps * params[:, 1] ) +  params[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = recreate_full_ymap(resdata[\"100206\"], y_mean_task_maps, resparam[\"100206\"])\n",
    "plot_29k(scipy.stats.zscore(yfull_task_data[\"100206\"][:, 6]), title=\"original\")\n",
    "plot_29k(data_[:, 6], title=\"recreated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare them for BrainSurfCNN (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from lib.default_config import task_names, tmsmall, smooth_lv, tmap_type, full_subj_path \n",
    "\n",
    "def get_hcp_task_contrast(subj, task_cope_ctr = ('SOCIAL', '6', 'TOM-RANDOM'), \n",
    "                          supfolder=\"HCP_1200/\", local_dir = \"/scratch/users/robert.scholz2/\",\n",
    "                          bma_slice=slice(None), scalar_slice=slice(None), zscore=False, v=False):\n",
    "  global task_fmri_sam, smooth_lv, tmsmall\n",
    "  (task, cope_num, contr) = task_cope_ctr\n",
    "  filen = f'{subj}/MNINonLinear/Results/tfMRI_{task}/tfMRI_{task}_hp200_s{smooth_lv}_level2{tmsmall}.feat/GrayordinatesStats/cope{cope_num}.feat/{tmap_type}.dtseries.nii'\n",
    "  if v: print(filen)\n",
    "  frmi = nib.load(local_dir + supfolder + filen)\n",
    "  frmi_data = frmi.get_fdata()[scalar_slice, bma_slice]\n",
    "  if zscore:\n",
    "    frmi_data = scipy.stats.zscore(frmi_data, axis=-1)\n",
    "  return frmi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/ngohgia/brain-surf-cnn/blob/master/preprocess/4_join_all_task_contrasts.py\n",
    "\n",
    "contrasts_dir = \"/scratch/users/robert.scholz2/hcp/joint_left_task_contrasts\"\n",
    "\n",
    "for subj in tqdm(all_subjs, desc=\"Concat and save task maps\"):\n",
    "  subj_task_data_file = os.path.join(contrasts_dir, \"%s_joint_L_task_contrasts.npy\" % subj)\n",
    "\n",
    "  if os.path.exists(subj_task_data_file):\n",
    "    print(f\"Skipping subject {subj} as the task maps file already seem to exist\")\n",
    "    continue;\n",
    "  \n",
    "  # a single task contrast returned by get_hcp_task_contrast has shape (1, 29696)\n",
    "  # we only get the left hemisphere\n",
    "  #tdata = [get_hcp_task_contrast(subj, ci, bma_slice=slice(0, 29696), zscore=1) for ci in contrast_info]\n",
    "  tdata = [get_hcp_task_contrast(subj, ci, bma_slice=slice(0, 29696), zscore=False) for ci in contrast_info]\n",
    "  subj_task_data = np.concatenate(tdata, axis=0) # (10, 29696)\n",
    "  np.save(subj_task_data_file, subj_task_data) \n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3.9-Torch (conda-env: bolts)",
   "language": "python",
   "name": "pytroch_nb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
